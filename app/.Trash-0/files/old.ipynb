{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook Temperature Humidity    Wind Play Tennis\n",
       "0      Sunny         Hot     High    Weak          No\n",
       "1      Sunny         Hot     High  Strong          No\n",
       "2   Overcast         Hot     High    Weak         Yes\n",
       "3       Rain        Mild     High    Weak         Yes\n",
       "4       Rain        Cool   Normal    Weak         Yes\n",
       "5       Rain        Cool   Normal  Strong          No\n",
       "6   Overcast        Cool   Normal  Strong         Yes\n",
       "7      Sunny        Mild     High    Weak          No\n",
       "8      Sunny        Cool   Normal    Weak         Yes\n",
       "9       Rain        Mild   Normal    Weak         Yes\n",
       "10     Sunny        Mild   Normal  Strong         Yes\n",
       "11  Overcast        Mild     High  Strong         Yes\n",
       "12  Overcast         Hot   Normal    Weak         Yes\n",
       "13      Rain        Mild     High  Strong          No"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data =pd.read_csv(\"PlayTennis.csv\") \n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Entropy for each feature of the dataset\n",
    "def feature_entropy(feature_value_data, target, class_list):\n",
    "    entropy = 0 \n",
    "    total_class_count = feature_value_data.shape[0] \n",
    "    for x in class_list:\n",
    "        each_class_count = feature_value_data[feature_value_data[target] == x].shape[0] \n",
    "        class_entropy = 0\n",
    "        if each_class_count != 0:\n",
    "            class_p = each_class_count/total_class_count \n",
    "            class_entropy = - class_p * np.log2(class_p) \n",
    "        entropy += class_entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(feature_name, train_data, target, class_list):\n",
    "    feature_info_gain = 0\n",
    "    feature_value_list = train_data[feature_name].unique()\n",
    "    total_row = train_data.shape[0]\n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = feature_entropy(feature_value_data, target, class_list)\n",
    "        feature_value_p = feature_value_count/total_row\n",
    "        feature_info_gain += feature_value_p * feature_value_entropy \n",
    "    return dataset_entropy(train_data, target, class_list) - feature_info_gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Total_Entropy for each classes\n",
    "def dataset_entropy(train_data, target, class_list):\n",
    "    total_entropy = 0\n",
    "    total_row = train_data.shape[0]    \n",
    "    for x in class_list: \n",
    "        each_class_count = train_data[train_data[target] == x].shape[0] \n",
    "        each_class_entropy = - (each_class_count/total_row)*np.log2(each_class_count/total_row) \n",
    "        total_entropy += each_class_entropy\n",
    "    return total_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature(train_data, target, class_list):\n",
    "    max_info_gain = 0\n",
    "    max_info_feature = None \n",
    "    feature_list = train_data.columns.drop(target)                                     \n",
    "    for feature in feature_list:\n",
    "        feature_info_gain = info_gain(feature, train_data, target, class_list)\n",
    "        if max_info_gain < feature_info_gain: \n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature          \n",
    "    return max_info_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outlook'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature(train_data,'Play Tennis',train_data['Play Tennis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final Decision_Tree is: {'Outlook': {'Rain': {'Wind': {'Strong': 'No', 'Weak': 'Yes'}}, 'Overcast': 'Yes', 'Sunny': {'Humidity': {'Normal': 'Yes', 'High': 'No'}}}}\n",
      "Accuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#Importing Train_Dataset \n",
    "train_data =pd.read_csv(\"PlayTennis.csv\") \n",
    "#print(train_data.head()) \n",
    "\n",
    "#Calculating Information_Gain\n",
    "def info_gain(feature_name, train_data, target, class_list):\n",
    "    feature_info_gain = 0\n",
    "    feature_value_list = train_data[feature_name].unique()\n",
    "    total_row = train_data.shape[0]\n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = feature_entropy(feature_value_data, target, class_list)\n",
    "        feature_value_p = feature_value_count/total_row\n",
    "        feature_info_gain += feature_value_p * feature_value_entropy \n",
    "    return dataset_entropy(train_data, target, class_list) - feature_info_gain \n",
    "\n",
    "#Calculating Total_Entropy for each classes\n",
    "def dataset_entropy(train_data, target, class_list):\n",
    "    total_entropy = 0\n",
    "    total_row = train_data.shape[0]    \n",
    "    for x in class_list: \n",
    "        each_class_count = train_data[train_data[target] == x].shape[0] \n",
    "        each_class_entropy = - (each_class_count/total_row)*np.log2(each_class_count/total_row) \n",
    "        total_entropy += each_class_entropy\n",
    "    return total_entropy\n",
    "    \n",
    "#Calculating Entropy for each feature of the dataset\n",
    "def feature_entropy(feature_value_data, target, class_list):\n",
    "    entropy = 0 \n",
    "    total_class_count = feature_value_data.shape[0] \n",
    "    for x in class_list:\n",
    "        each_class_count = feature_value_data[feature_value_data[target] == x].shape[0] \n",
    "        class_entropy = 0\n",
    "        if each_class_count != 0:\n",
    "            class_p = each_class_count/total_class_count \n",
    "            class_entropy = - class_p * np.log2(class_p) \n",
    "        entropy += class_entropy\n",
    "    return entropy\n",
    "\n",
    "#Finding the best feature that has the highest Information_Gain\n",
    "def best_feature(train_data, target, class_list):\n",
    "    max_info_gain = 0\n",
    "    max_info_feature = None \n",
    "    feature_list = train_data.columns.drop(target)                                     \n",
    "    for feature in feature_list:\n",
    "        feature_info_gain = info_gain(feature, train_data, target, class_list)\n",
    "        if max_info_gain < feature_info_gain: \n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature          \n",
    "    return max_info_feature\n",
    "\n",
    "#Building Branches of Decision_Tree                 \n",
    "def sub_tree(feature_name, train_data, target, class_list):\n",
    "    tree = {} \n",
    "    feature_value_count = train_data[feature_name].value_counts(sort=False)\n",
    "    for feature_value, count in feature_value_count.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        leaf_node = False \n",
    "        for x in class_list: \n",
    "            each_class_count = feature_value_data[feature_value_data[target] == x].shape[0] \n",
    "            if each_class_count == count: #Reaching to a leaf_node\n",
    "                tree[feature_value] = x \n",
    "                train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                leaf_node = True\n",
    "        if not leaf_node: \n",
    "            tree[feature_value] = \"Branch\" #Tree should be expanded\n",
    "    return tree, train_data\n",
    "\n",
    "#Building Decision_Tree\n",
    "def ID3(root, parent_node, train_data, target, class_list):\n",
    "    if train_data.shape[0] != 0: \n",
    "        max_info_feature = best_feature(train_data, target, class_list) \n",
    "        tree, train_data = sub_tree(max_info_feature, train_data, target, class_list) \n",
    "        next_root = None \n",
    "        if parent_node != None: \n",
    "            root[parent_node] = dict()\n",
    "            root[parent_node][max_info_feature] = tree\n",
    "            next_root = root[parent_node][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]      \n",
    "        for node, branch in list(next_root.items()): \n",
    "            if branch == \"Branch\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] \n",
    "                ID3(next_root, node, feature_value_data, target, class_list)\n",
    "\n",
    "#Predicting New_new_instances for Test_dataset\n",
    "def predict(tree, new_instance):\n",
    "    if not isinstance(tree, dict): #Whether reaching a leaf_node or not\n",
    "        return tree \n",
    "    else:\n",
    "        root_node = next(iter(tree))\n",
    "        feature_value = new_instance[root_node] \n",
    "        if feature_value in tree[root_node]: \n",
    "            return predict(tree[root_node][feature_value], new_instance) \n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "#Starting Training the dataset with making a Decicion_Tree \n",
    "target=\"Play Tennis\"\n",
    "tree = {} \n",
    "class_list = train_data[target].unique() \n",
    "ID3(tree, None, train_data, target, class_list)\n",
    "print ('The final Decision_Tree is:',tree)\n",
    "\n",
    "#Importing Test_Dataset for prediction of new_new_instances\n",
    "test_data = pd.read_csv(\"PlayTennis_test.csv\")\n",
    "\n",
    "#Starting Testing new_data as Test_dataset & calculating Accuracy \n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "for index, row in test_data.iterrows(): \n",
    "    result = predict(tree, test_data.iloc[index]) \n",
    "    if result == test_data[target].iloc[index]: \n",
    "        correct_count += 1 \n",
    "    else:\n",
    "        wrong_count+= 1 \n",
    "accuracy =  correct_count / ( correct_count + wrong_count) \n",
    "print ('Accuracy=', accuracy)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
